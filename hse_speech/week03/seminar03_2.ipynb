{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc3c8b2-35fb-44c3-800e-ef9bc13a9231",
   "metadata": {},
   "source": [
    "# Decoding CTC output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b923207-7a92-47f3-9f8f-1448b2ba4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "# Load precomputed CTC output\n",
    "with open('mystery_records.pickle', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
    "log_probs = batch[\"log_probs\"]\n",
    "\n",
    "# Dictionary with index to character mapping\n",
    "ind2char = batch[\"ind2char\"]\n",
    "\n",
    "# Index of special EMPTY token\n",
    "EMPTY_TOK = '^'\n",
    "EMPTY_IND = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922cbf65-fbaf-48d5-8605-ea41c3f80590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) we nostrngesto love you know therols and so do i a foll commitment what i thinking of you wolden get this from any ather guy\n",
      "1)  never gona give you up never donelet you down never go arun around and deset you never gon a make you cri never gonna say good by\n"
     ]
    }
   ],
   "source": [
    "def ctc_decode(inds, ind2char):\n",
    "    decoded = []\n",
    "    prev_idx = EMPTY_IND\n",
    "    for idx in inds:\n",
    "        if idx != prev_idx:\n",
    "            if idx != EMPTY_IND:\n",
    "                decoded.append(ind2char[idx])\n",
    "            prev_idx = idx\n",
    "    return ''.join(decoded)\n",
    "\n",
    "for i, rec in enumerate(log_probs):\n",
    "    text = ctc_decode(rec.argmax(-1).numpy(), ind2char)\n",
    "    print(f\"{i}) {text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c4d50-e633-4e85-8842-a6b50602b70f",
   "metadata": {},
   "source": [
    "# Computing WER and CER\n",
    "Task: Implemet WER and CER metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca11f70-ee02-4765-b542-96186781a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for fast quick calculation of edit distance\n",
    "import editdistance\n",
    "\n",
    "def calc_wer(target_text: str, pred_text: str):\n",
    "    if len(target_text) == 0:\n",
    "        return len(pred_text.split())\n",
    "    return editdistance.eval(target_text.split(), pred_text.split()) / len(target_text.split())\n",
    "    \n",
    "\n",
    "def calc_cer(target_text: str, pred_text: str):\n",
    "    if len(target_text) == 0:\n",
    "        return len(pred_text)\n",
    "    return editdistance.eval(target_text, pred_text) / len(target_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c391511-7469-4ed8-bd26-057c4fde4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for target, pred, expected_wer, expected_cer in [\n",
    "    (\"if you can not measure it you can not improve it\", \n",
    "     \"if you can nt measure t yo can not i\", \n",
    "     0.454, 0.25),\n",
    "    (\"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     \"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     0.0, 0.0),\n",
    "    (\"one measurement is worth a thousand expert opinions\", \n",
    "     \"one  is worth thousand opinions\", \n",
    "     0.375, 0.392)\n",
    "]:\n",
    "    wer = calc_wer(target, pred)\n",
    "    cer = calc_cer(target, pred)\n",
    "    assert np.isclose(wer, expected_wer, atol=1e-3), f\"true: {target}, pred: {pred}, expected wer {expected_wer} != your wer {wer}\"\n",
    "    assert np.isclose(cer, expected_cer, atol=1e-3), f\"true: {target}, pred: {pred}, expected cer {expected_cer} != your cer {cer}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefd76b-66d4-4b1e-ae1d-be6b7336a160",
   "metadata": {},
   "source": [
    "Task: come up with such a pair of target-prediction texts, so the\n",
    "1) WER > 1.0\n",
    "2) CER > WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11bceaaf-7b17-466b-ac17-855e4d54cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) WER > 1.0\n",
    "# your code here\n",
    "target, prediction = \"hello\" , \"hello my dear friend\"\n",
    "assert calc_wer(target, prediction) > 1.0\n",
    "\n",
    "# 2) CER > WER\n",
    "# your code here\n",
    "target, prediction = \"i love you\", \"fhadfklas faldfja fjak\"\n",
    "assert calc_wer(target, prediction) < calc_cer(target, prediction) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1fb97-4853-4190-835d-31ead094679c",
   "metadata": {},
   "source": [
    "# Beam search\n",
    "Task: implement beam-search on CTC outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8e1c37a-93be-47a1-8211-9b47d0721d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed CTC output\n",
    "with open('lj_batch.pickle', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
    "log_probs = batch[\"log_probs\"]\n",
    "\n",
    "# Dictionary with index to character mapping\n",
    "ind2char = batch[\"ind2char\"]\n",
    "\n",
    "true_texts = batch[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ae1f264-33cb-4c4d-b959-823d07843936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def expand_and_merge(hyposesis, next_token_probs, ind2char):\n",
    "    new_hyposesis = defaultdict(float)\n",
    "\n",
    "    for i, new_token_prob in enumerate(next_token_probs):\n",
    "        cur_char = ind2char[i]\n",
    "        for (prefix, last_char), prob in hyposesis.items():\n",
    "            if cur_char != last_char and cur_char != EMPTY_TOK:\n",
    "                prefix += cur_char\n",
    "\n",
    "            new_hyposesis[(prefix, cur_char)] += prob * new_token_prob\n",
    "\n",
    "    return new_hyposesis\n",
    "\n",
    "\n",
    "def truncate(hyposesis, beam_size):\n",
    "    return dict(\n",
    "        sorted(hyposesis.items(), key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "    )\n",
    "\n",
    "\n",
    "def ctc_beam_search(probs, beam_size, ind2char):\n",
    "    hyposesis = {(\"\", EMPTY_TOK): 1.0}\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        hyposesis = expand_and_merge(hyposesis, probs[i], ind2char)\n",
    "        hyposesis = truncate(hyposesis, beam_size)\n",
    "    return sorted(\n",
    "        [(prefix, prob) for (prefix, _), prob in hyposesis.items()],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "\n",
    "bs_results = []\n",
    "for log_probs_line in log_probs:\n",
    "    bs_results.append(\n",
    "        ctc_beam_search(log_probs_line.exp().numpy(), 100, ind2char)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "239ed9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he wl ge to her iand tell her all hisan ly omblications',\n",
       "  1.262360559344665e-10),\n",
       " ('he wl ge to her and tell her all hisan ly omblications',\n",
       "  1.2342273783422715e-10),\n",
       " ('he wl ge to her iand tell her all hisanly omblications',\n",
       "  1.1286613183814588e-10),\n",
       " ('he wl ge to her and tell her all hisanly omblications',\n",
       "  1.1035077812835402e-10),\n",
       " ('he wl ge to her iand tell her all hisan ly omblocations',\n",
       "  1.0519465737579816e-10)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_results[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e6d7249-aed1-4ff3-8ce2-20978320ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  he would go to her and tell her all his family complications\n",
      "Argmax: he wld ge toher iand tell her all mhisan ly omblications --- (CER: 0.200)\n",
      "1) 'he wl ge to her iand tell her all hisan ly omblications' --- (CER: 0.183)\n",
      "2) 'he wl ge to her and tell her all hisan ly omblications' --- (CER: 0.167)\n",
      "3) 'he wl ge to her iand tell her all hisanly omblications' --- (CER: 0.183)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  he did not say the last as a boast but merely as an assurance to the liveryman who he saw was anxious on his account\n",
      "Argmax: he did not sad the last is a bost but mearlioves an asurance to the livery man who re saw was anxes on his account --- (CER: 0.129)\n",
      "1) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.112)\n",
      "2) 'he did not say the last as a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.103)\n",
      "3) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxies on his account' --- (CER: 0.103)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  he started to conscious confusion only neither knowing where he was nor what he did\n",
      "Argmax: he started to consces confusion only neither knowing where he was nor what he did --- (CER: 0.036)\n",
      "1) 'he started to consces confusion only neither knowing where he was nor what he did' --- (CER: 0.036)\n",
      "2) 'he started to consces confusion only neither knowwing where he was nor what he did' --- (CER: 0.048)\n",
      "3) 'he started to consces confusion only neither knowing where he was nor what he did ' --- (CER: 0.048)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  i'm here because the matter is of utmost importance and brandd is the one i must see now stand aside\n",
      "Argmax: imcere because he matderacis of ut most omportanceand brand is o vammasea nhostend aside --- (CER: 0.280)\n",
      "1) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nho stend aside' --- (CER: 0.260)\n",
      "2) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhostend aside' --- (CER: 0.270)\n",
      "3) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhestend aside' --- (CER: 0.270)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  of course it ain't said missus bozzle\n",
      "Argmax: of coursit int said missus bozol --- (CER: 0.162)\n",
      "1) 'of cours it int said missus bozol' --- (CER: 0.135)\n",
      "2) 'of cours it int said missus bozol ' --- (CER: 0.135)\n",
      "3) 'of cours it int said missus bozal' --- (CER: 0.135)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  mister verloc was fully responsive now\n",
      "Argmax: mister volockwass fuly respons of mow --- (CER: 0.237)\n",
      "1) 'mister volockwass fuly respons of mow' --- (CER: 0.237)\n",
      "2) 'mister volockwass fuli respons of mow' --- (CER: 0.263)\n",
      "3) 'mister volockwass fuly resplons of mow' --- (CER: 0.263)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  oh what shall we do for a home\n",
      "Argmax: oh what shal we do for a whom --- (CER: 0.100)\n",
      "1) 'oh what shal we do for a whom' --- (CER: 0.100)\n",
      "2) 'ohh what shal we do for a whom' --- (CER: 0.133)\n",
      "3) 'oh what shal we do for a whom ' --- (CER: 0.100)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  line of battle was formed on the north bank of stone's river on the yankee side\n",
      "Argmax: line of battle was formed on the north bank of stones river on the yanky sidt  --- (CER: 0.063)\n",
      "1) 'wine of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.063)\n",
      "2) 'line of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.051)\n",
      "3) 'wine of battle was formed on the north bank of stones river on the yanky side' --- (CER: 0.051)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  from fifteen to twenty minutes will be required to bake them nicely\n",
      "Argmax: fror fifteen t teny minites will be required to bake the nicely --- (CER: 0.090)\n",
      "1) 'fror fifteengt tweny minites will be required to bake the nicely' --- (CER: 0.090)\n",
      "2) 'fror fifteen t tweny minites will be required to bake the nicely' --- (CER: 0.075)\n",
      "3) 'fror fifteengt tweny minutes will be required to bake the nicely' --- (CER: 0.075)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  whom is he going to flog now\n",
      "Argmax: whoom is agoing to flag no --- (CER: 0.214)\n",
      "1) 'whoom is agoing to flagd now' --- (CER: 0.214)\n",
      "2) 'whoom is agoing to flogd now' --- (CER: 0.179)\n",
      "3) 'whoom is agoing to flaugd now' --- (CER: 0.250)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(true_texts)):\n",
    "    beam_search_hypos = bs_results[i][:3]\n",
    "    true_text = true_texts[i]\n",
    "    argmax_text = ctc_decode(log_probs[i].numpy().argmax(-1), ind2char)\n",
    "    print(\"True: \", true_text)\n",
    "    print(f\"Argmax: {argmax_text} --- (CER: {calc_cer(true_text, argmax_text):.3f})\")\n",
    "    for ind, (hypo, score) in enumerate(beam_search_hypos):\n",
    "        print(f\"{ind+1}) '{hypo}' --- (CER: {calc_cer(true_text, hypo):.3f})\")\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad40d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
